{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfomer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you\n"
     ]
    }
   ],
   "source": [
    "# read the dataset\n",
    "with open('./data/input.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# print out the first 100 characters\n",
    "print(text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters: 65\n",
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "# create a list of all characters in the text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# print out the number of unique characters\n",
    "print('Number of unique characters: {}'.format(vocab_size))\n",
    "# print out the characters\n",
    "print(''.join(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'A', 14: 'B', 15: 'C', 16: 'D', 17: 'E', 18: 'F', 19: 'G', 20: 'H', 21: 'I', 22: 'J', 23: 'K', 24: 'L', 25: 'M', 26: 'N', 27: 'O', 28: 'P', 29: 'Q', 30: 'R', 31: 'S', 32: 'T', 33: 'U', 34: 'V', 35: 'W', 36: 'X', 37: 'Y', 38: 'Z', 39: 'a', 40: 'b', 41: 'c', 42: 'd', 43: 'e', 44: 'f', 45: 'g', 46: 'h', 47: 'i', 48: 'j', 49: 'k', 50: 'l', 51: 'm', 52: 'n', 53: 'o', 54: 'p', 55: 'q', 56: 'r', 57: 's', 58: 't', 59: 'u', 60: 'v', 61: 'w', 62: 'x', 63: 'y', 64: 'z'}\n",
      "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary that maps integers to characters and vice versa\n",
    "int2char = dict(enumerate(chars))\n",
    "char2int = {ch: ii for ii, ch in int2char.items()}\n",
    "\n",
    "print(int2char)\n",
    "print(char2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 43, 50, 50, 53]\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "# create encode and decode functions\n",
    "encode = lambda text: [char2int[ch] for ch in text]\n",
    "decode = lambda int_arr: ''.join([int2char[ii] for ii in int_arr])\n",
    "\n",
    "# encode the text\n",
    "print(encode('hello'))\n",
    "print(decode(encode('hello')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 47, 56,  ..., 45,  8,  0]) torch.Size([1115394])\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43])\n"
     ]
    }
   ],
   "source": [
    "# encode the whole text\n",
    "text_data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(text_data, text_data.shape)\n",
    "print(text_data[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1003854]) torch.Size([111540])\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into train and test sets\n",
    "train_n = int(text_data.shape[0] * 0.9)\n",
    "train_data = text_data[:train_n]\n",
    "test_data = text_data[train_n:]\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: tensor([18]), target: 47\n",
      "context: tensor([18, 47]), target: 56\n",
      "context: tensor([18, 47, 56]), target: 57\n",
      "context: tensor([18, 47, 56, 57]), target: 58\n",
      "context: tensor([18, 47, 56, 57, 58]), target: 1\n",
      "context: tensor([18, 47, 56, 57, 58,  1]), target: 15\n",
      "context: tensor([18, 47, 56, 57, 58,  1, 15]), target: 47\n",
      "context: tensor([18, 47, 56, 57, 58,  1, 15, 47]), target: 58\n"
     ]
    }
   ],
   "source": [
    "block_size = 8\n",
    "\n",
    "# show context and target\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f'context: {context}, target: {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a batch generator\n",
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate random starting indices for the batch data\n",
    "    data = train_data if split == 'train' else test_data\n",
    "    # get the starting indices for the batch data\n",
    "    starts = torch.randint(high=data.shape[0] - block_size, size=(batch_size,))\n",
    "    # get the batch data\n",
    "    batch_x = [data[start:start+block_size] for start in starts]\n",
    "    batch_y = [data[start+1:start+block_size+1] for start in starts]\n",
    "    # convert the list to tensors\n",
    "    batch_x, batch_y = torch.stack(batch_x), torch.stack(batch_y)\n",
    "\n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: \n",
      " torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets: \n",
      " torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n"
     ]
    }
   ],
   "source": [
    "# take a look at the batch data\n",
    "xb, yb = get_batch('train')\n",
    "print(\"inputs: \\n\", xb.shape)\n",
    "print(xb)\n",
    "print(\"targets: \\n\", yb.shape)\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0:\n",
      "context: tensor([24]), target: 43\n",
      "context: tensor([24, 43]), target: 58\n",
      "context: tensor([24, 43, 58]), target: 5\n",
      "context: tensor([24, 43, 58,  5]), target: 57\n",
      "context: tensor([24, 43, 58,  5, 57]), target: 1\n",
      "context: tensor([24, 43, 58,  5, 57,  1]), target: 46\n",
      "context: tensor([24, 43, 58,  5, 57,  1, 46]), target: 43\n",
      "context: tensor([24, 43, 58,  5, 57,  1, 46, 43]), target: 39\n",
      "batch 1:\n",
      "context: tensor([44]), target: 53\n",
      "context: tensor([44, 53]), target: 56\n",
      "context: tensor([44, 53, 56]), target: 1\n",
      "context: tensor([44, 53, 56,  1]), target: 58\n",
      "context: tensor([44, 53, 56,  1, 58]), target: 46\n",
      "context: tensor([44, 53, 56,  1, 58, 46]), target: 39\n",
      "context: tensor([44, 53, 56,  1, 58, 46, 39]), target: 58\n",
      "context: tensor([44, 53, 56,  1, 58, 46, 39, 58]), target: 1\n",
      "batch 2:\n",
      "context: tensor([52]), target: 58\n",
      "context: tensor([52, 58]), target: 1\n",
      "context: tensor([52, 58,  1]), target: 58\n",
      "context: tensor([52, 58,  1, 58]), target: 46\n",
      "context: tensor([52, 58,  1, 58, 46]), target: 39\n",
      "context: tensor([52, 58,  1, 58, 46, 39]), target: 58\n",
      "context: tensor([52, 58,  1, 58, 46, 39, 58]), target: 1\n",
      "context: tensor([52, 58,  1, 58, 46, 39, 58,  1]), target: 46\n",
      "batch 3:\n",
      "context: tensor([25]), target: 17\n",
      "context: tensor([25, 17]), target: 27\n",
      "context: tensor([25, 17, 27]), target: 10\n",
      "context: tensor([25, 17, 27, 10]), target: 0\n",
      "context: tensor([25, 17, 27, 10,  0]), target: 21\n",
      "context: tensor([25, 17, 27, 10,  0, 21]), target: 1\n",
      "context: tensor([25, 17, 27, 10,  0, 21,  1]), target: 54\n",
      "context: tensor([25, 17, 27, 10,  0, 21,  1, 54]), target: 39\n"
     ]
    }
   ],
   "source": [
    "for b in range(batch_size):\n",
    "    print(f'batch {b}:')\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f'context: {context}, target: {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n"
     ]
    }
   ],
   "source": [
    "print(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 11])\n",
      "tensor([ 0, 31, 56, 12, 55, 28,  7, 29, 35, 49, 58])\n"
     ]
    }
   ],
   "source": [
    "# bigram model\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # embedding layer\n",
    "        # it is a matrix of size vocab_size x vocab_size\n",
    "        # which serves as a lookup table for the token embeddings\n",
    "        # what is lookup table?\n",
    "        # it is a table that maps integers to embeddings\n",
    "        # right now, it is initialized randomly\n",
    "        # but it will be trained later and learned from the data\n",
    "        # here the vector size is the same as the vocab size\n",
    "        self.token_embeddings = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    \n",
    "    def forward(self, idx, target=None):\n",
    "\n",
    "        # get the token embeddings  (batch_size, block_size, channel_size)\n",
    "        # block_size is the number of tokens in the context\n",
    "        # which is also called the time steps, that's why it is T\n",
    "        logits = self.token_embeddings(idx) #(B, T, C)\n",
    "\n",
    "        if target is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # reshape the embeddings to (batch_size * block_size, channel_size)\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            target = target.view(B * T)\n",
    "            # compute the loss\n",
    "            loss = F.cross_entropy(logits, target)\n",
    "    \n",
    "        return logits, loss \n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (batch_size, block_size)  which is (B, T)\n",
    "        # which means the context for each batch\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            # self(idx, target) is the same as self.forward(idx, target)\n",
    "            logits, loss = self(idx)\n",
    "            # get the logit for the last token in the context\n",
    "            # which is the token we want to predict\n",
    "            # here logits is (batch_size, block_size, channel_size)\n",
    "            # beacause loss=None, we did not reshape the logits\n",
    "            logits = logits[:, -1, :]\n",
    "            # the shape now is (batch_size, channel_size)\n",
    "            # dim=-1 means the last dimension, which is the channel_size\n",
    "            # we want to normalize the logits to get the probabilities\n",
    "            # in the dimension of channel_size\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            # append the new token to the context\n",
    "            idx = torch.cat([idx, idx_next], dim=1)\n",
    "\n",
    "        return idx\n",
    "\n",
    "    \n",
    "\n",
    "# create the model\n",
    "m1 = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m1(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "# we are trying to generate 10 new tokens\n",
    "foo = m1.generate(idx=torch.zeros((1, 1), dtype=torch.long), max_new_tokens=10)\n",
    "print(foo.shape)\n",
    "print(foo[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.174387269895637"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's calculate the log likelihood of the model\n",
    "# when we randomly initialize the model, the log likelihood is\n",
    "- np.log(1/len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an optimizer\n",
    "optimizer = torch.optim.Adam(m1.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0, loss 2.6934\n",
      "iteration 300, loss 2.8176\n",
      "iteration 600, loss 2.6193\n",
      "iteration 900, loss 2.5633\n",
      "iteration 1200, loss 2.4729\n",
      "iteration 1500, loss 2.5656\n",
      "iteration 1800, loss 2.5707\n",
      "iteration 2100, loss 2.5902\n",
      "iteration 2400, loss 2.5247\n",
      "iteration 2700, loss 2.5106\n",
      "iteration 3000, loss 2.4144\n",
      "iteration 3300, loss 2.4463\n",
      "iteration 3600, loss 2.5506\n",
      "iteration 3900, loss 2.4637\n",
      "iteration 4200, loss 2.4787\n",
      "iteration 4500, loss 2.4445\n",
      "iteration 4800, loss 2.4464\n"
     ]
    }
   ],
   "source": [
    "# batch size = 32\n",
    "batch_size = 32\n",
    "\n",
    "for i in range(5000):\n",
    "\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # forward pass\n",
    "    logits, loss = m1(xb, yb)\n",
    "    # clear the gradients\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    # update the parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 300 == 0:\n",
    "        print(f'iteration {i}, loss {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bl s my tln an My fe res angor:\n",
      "\n",
      "\n",
      "WAmell ssty t g sh niene himp pl hte sept pe o: lea, f her ger ft \n"
     ]
    }
   ],
   "source": [
    "foo = m1.generate(idx=torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)\n",
    "print(decode(foo[0].tolist()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The matematical tricks of self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 2])\n"
     ]
    }
   ],
   "source": [
    "# simulate the self-attention mechanism\n",
    "torch.manual_seed\n",
    "B, T, C = 4, 8, 2  # batch_size, block_size(time), channel_size\n",
    "foox = torch.randn((B, T, C))\n",
    "print(foox.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow = torch.zeros((B, T, C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = foox[b, :t+1]\n",
    "        xbow[b, t] = xprev.mean(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3271,  0.5617],\n",
       "        [-1.7239, -0.7233],\n",
       "        [ 1.8522,  1.6077],\n",
       "        [-0.1108, -1.9461],\n",
       "        [ 0.4432, -0.6504],\n",
       "        [ 1.7156, -0.4671],\n",
       "        [-1.4578,  0.9734],\n",
       "        [ 1.9970, -0.6166]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foox[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3271,  0.5617],\n",
       "        [-1.0255, -0.0808],\n",
       "        [-0.0663,  0.4820],\n",
       "        [-0.0774, -0.1250],\n",
       "        [ 0.0267, -0.2301],\n",
       "        [ 0.3082, -0.2696],\n",
       "        [ 0.0559, -0.0920],\n",
       "        [ 0.2986, -0.1576]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[5., 7.],\n",
      "        [2., 0.],\n",
      "        [5., 3.]])\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[5.0000, 7.0000],\n",
       "        [3.5000, 3.5000],\n",
       "        [4.0000, 3.3333]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "a = torch.tril(torch.ones((3, 3)))\n",
    "print(a)\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "print(b)\n",
    "a @ b\n",
    "\n",
    "a = a/ a.sum(dim=1, keepdim=True)\n",
    "print(a)\n",
    "a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    }
   ],
   "source": [
    "wei = torch.tril(torch.ones((T, T)))\n",
    "wei = wei / wei.sum(dim=1, keepdim=True)\n",
    "print(wei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 2])\n"
     ]
    }
   ],
   "source": [
    "xbow2 = wei @ foox\n",
    "print(xbow2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    }
   ],
   "source": [
    "# version 3 using softmax\n",
    "tril3 = torch.tril(torch.ones((T, T)))\n",
    "print(tril3)\n",
    "wei3 = torch.zeros((T, T))\n",
    "print(wei3)\n",
    "wei3 = wei3.masked_fill(tril3 == 0, float('-inf'))\n",
    "print(wei3)\n",
    "# call softmax\n",
    "wei3 = F.softmax(wei3, dim=1)\n",
    "print(wei3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(wei, wei3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-attention demo\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 32 # batch_size, block_size(time), channel_size\n",
    "# channel_size is the embedding size\n",
    "x = torch.randn((B, T, C))\n",
    "\n",
    "\n",
    "# let's add query, key, value\n",
    "# set head_size = 16, which means we have 2 heads\n",
    "# because 32 / 16 = 2\n",
    "head_size = 16\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "x_q = query(x)  # (B, T, head_size)\n",
    "x_k = key(x)  # (B, T, head_size)\n",
    "\n",
    "wei = x_q @ x_k.transpose(1, 2)  # (B, T, head_size) @ (B, head_size, T) = (B, T, T)\n",
    "\n",
    "\n",
    "# average of the previous tokens\n",
    "tril = torch.tril(torch.ones((T, T)))\n",
    "# # wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "# print(wei.shape)\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "# print(wei.shape)\n",
    "v = value(x)  # (B, T, head_size)\n",
    "out = wei @ v  # (B, T, T) @ (B, T, head_size) = (B, T, head_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5877, 0.4123, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4457, 0.2810, 0.2733, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2220, 0.7496, 0.0175, 0.0109, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0379, 0.0124, 0.0412, 0.0630, 0.8454, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5497, 0.2187, 0.0185, 0.0239, 0.1831, 0.0062, 0.0000, 0.0000],\n",
       "        [0.2576, 0.0830, 0.0946, 0.0241, 0.1273, 0.3627, 0.0507, 0.0000],\n",
       "        [0.0499, 0.1052, 0.0302, 0.0281, 0.1980, 0.2657, 0.1755, 0.1474]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
