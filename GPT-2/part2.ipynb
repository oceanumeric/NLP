{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Neural Probabilistic Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import key packages\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# retina display\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 32033\n"
     ]
    }
   ],
   "source": [
    "# read the dataset\n",
    "words = open('./data/names.txt', 'r').read().splitlines()\n",
    "print('Number of words:', len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters: 26\n"
     ]
    }
   ],
   "source": [
    "# build up the dictionary for mapping characters to integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "print('Number of characters:', len(chars))\n",
    "# chars to integers\n",
    "char2int = {c: i+1 for i, c in enumerate(chars)}\n",
    "# add . as the padding character\n",
    "char2int['.'] = 0\n",
    "# integers to chars\n",
    "int2char = {i: c for c, i in char2int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char2int: {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '.': 0}\n"
     ]
    }
   ],
   "source": [
    "print('char2int:', char2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int2char: {1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "print('int2char:', int2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "   emm --> a\n",
      "olivia\n",
      "   oli --> v\n",
      "   liv --> i\n",
      "   ivi --> a\n",
      "ava\n",
      "isabella\n",
      "   isa --> b\n",
      "   sab --> e\n",
      "   abe --> l\n",
      "   bel --> l\n",
      "   ell --> a\n",
      "sophia\n",
      "   sop --> h\n",
      "   oph --> i\n",
      "   phi --> a\n"
     ]
    }
   ],
   "source": [
    "# build up the dataset\n",
    "block_size = 3 # the length of sequences of input data\n",
    "X, Y = [], []\n",
    "\n",
    "for word in words[:5]:\n",
    "    print(word)\n",
    "    for i in range(0, len(word) - block_size):\n",
    "        # rolling window of block_size\n",
    "        X.append([char2int[c] for c in word[i:i+block_size]])\n",
    "        Y.append(char2int[word[i+block_size]])\n",
    "        print('  ', word[i:i+block_size], '-->', word[i+block_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... --> e\n",
      "..e --> m\n",
      ".em --> m\n",
      "emm --> a\n",
      "mma --> .\n",
      "olivia\n",
      "... --> o\n",
      "..o --> l\n",
      ".ol --> i\n",
      "oli --> v\n",
      "liv --> i\n",
      "ivi --> a\n",
      "via --> .\n",
      "ava\n",
      "... --> a\n",
      "..a --> v\n",
      ".av --> a\n",
      "ava --> .\n",
      "isabella\n",
      "... --> i\n",
      "..i --> s\n",
      ".is --> a\n",
      "isa --> b\n",
      "sab --> e\n",
      "abe --> l\n",
      "bel --> l\n",
      "ell --> a\n",
      "lla --> .\n",
      "sophia\n",
      "... --> s\n",
      "..s --> o\n",
      ".so --> p\n",
      "sop --> h\n",
      "oph --> i\n",
      "phi --> a\n",
      "hia --> .\n"
     ]
    }
   ],
   "source": [
    "# the above method does not add '.'\n",
    "block_size = 3 # the length of sequences of input data\n",
    "X, Y = [], []\n",
    "\n",
    "for word in words[:5]:\n",
    "    print(word)\n",
    "    # initial context by building up the padding characters\n",
    "    context = [0] * block_size\n",
    "    for ch in word+ '.':\n",
    "        idx = char2int[ch]\n",
    "        X.append(context)\n",
    "        Y.append(idx)\n",
    "        # print the context and the next character\n",
    "        print(''.join([int2char[i] for i in context]), '-->', ch)\n",
    "        # update the context by rolling\n",
    "        context = context[1:] + [idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensors\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3]) torch.Size([32]) torch.int64 torch.int64\n"
     ]
    }
   ],
   "source": [
    "# right now 32 = document size, 3 = block size\n",
    "print(X.shape, Y.shape, X.dtype, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0,  0],\n",
      "        [ 0,  0,  5],\n",
      "        [ 0,  5, 13],\n",
      "        [ 5, 13, 13],\n",
      "        [13, 13,  1]]) tensor([ 5, 13, 13,  1,  0])\n"
     ]
    }
   ],
   "source": [
    "print(X[:5], Y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 2])\n"
     ]
    }
   ],
   "source": [
    "# initialize the lookup table\n",
    "C_lookup = torch.randn(len(char2int), 2, requires_grad=True)\n",
    "print(C_lookup.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4977,  0.8756],\n",
       "        [-0.4006,  0.6435],\n",
       "        [ 1.7300, -0.0446],\n",
       "        [ 0.0446, -2.9870],\n",
       "        [ 1.9398, -0.2666],\n",
       "        [ 0.0790, -0.2298],\n",
       "        [ 2.2499, -2.9052],\n",
       "        [ 1.3151,  0.2223],\n",
       "        [-0.1359,  1.1480],\n",
       "        [ 1.0357, -0.6063],\n",
       "        [ 0.1686, -1.5691],\n",
       "        [ 0.4391, -1.6887],\n",
       "        [ 0.2008, -1.5794],\n",
       "        [ 0.7514, -0.3242],\n",
       "        [-0.2992,  0.0307],\n",
       "        [-0.3125, -0.0838],\n",
       "        [ 0.5809,  1.7678],\n",
       "        [ 1.1271,  0.8043],\n",
       "        [ 0.3943, -1.1657],\n",
       "        [-0.4073,  2.0113],\n",
       "        [-0.6337, -0.0362],\n",
       "        [ 0.7606,  0.8676],\n",
       "        [-0.5598,  1.4374],\n",
       "        [-0.9409,  0.4591],\n",
       "        [ 0.0696,  0.4772],\n",
       "        [-0.2564,  0.0926],\n",
       "        [-0.1636, -1.1153]], requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_lookup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time to have some reflections. Since we are doing a sequence to sequence model. We first need to construct our sequences:\n",
    "\n",
    "- choosing input block size as 3 (rolling window)\n",
    "- choosing output size as 1 (next word)\n",
    "\n",
    "After that, we constructed our look-up table, which is an embedding layer. The embedding layer is a matrix of size (vocab_size, embedding_size). The embedding_size is a hyperparameter. In our case we have \n",
    "\n",
    "- vocab_size = 27\n",
    "- embedding_size = 2 (to keep it simple)\n",
    "\n",
    "Since each input sequence has 3 words, we have 3 embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4977, 0.8756], grad_fn=<SelectBackward0>)\n",
      "tensor([[ 0.0446, -2.9870],\n",
      "        [ 0.0790, -0.2298],\n",
      "        [ 1.0357, -0.6063]], grad_fn=<IndexBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# example of getting embedding vectors\n",
    "print(C_lookup[0])\n",
    "print(C_lookup[[3, 5, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# embedding all the characters in the input sequences\n",
    "X_embed = C_lookup[X]\n",
    "print(X_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 100]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# create the hidden layer\n",
    "# input dimension = 2x3 = 6, output dimension = 100\n",
    "# set seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "W1 = torch.randn(6, 100, requires_grad=True)\n",
    "b1 = torch.randn(100, requires_grad=True)\n",
    "print(W1.shape, b1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 6])\n"
     ]
    }
   ],
   "source": [
    "# reshape the input sequences\n",
    "X_embed = X_embed.view(-1, 6)\n",
    "print(X_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 100])\n"
     ]
    }
   ],
   "source": [
    "# calculate the hidden layer\n",
    "H = torch.tanh(X_embed @ W1 + b1)\n",
    "print(H.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 27]) torch.Size([27])\n"
     ]
    }
   ],
   "source": [
    "# output layer\n",
    "# input dimension = 100, output dimension = 27\n",
    "W2 = torch.randn(100, len(char2int), requires_grad=True)\n",
    "b2 = torch.randn(len(char2int), requires_grad=True)\n",
    "print(W2.shape, b2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 27])\n",
      "torch.Size([32, 27])\n"
     ]
    }
   ],
   "source": [
    "# calculate the output layer step by step\n",
    "# logistic function\n",
    "logits = H @ W2 + b2\n",
    "print(logits.shape)\n",
    "# exponentiation\n",
    "counts = logits.exp()\n",
    "# normalization\n",
    "probs = counts / counts.sum(dim=1, keepdim=True)\n",
    "print(probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
      "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1295e-11, 3.9312e-02, 3.2966e-02, 6.9774e-08, 1.1928e-11, 3.2660e-10,\n",
       "        5.5922e-07, 9.6566e-01, 1.6914e-14, 6.2913e-08, 9.9986e-01, 1.3768e-06,\n",
       "        1.9034e-08, 3.9118e-08, 2.6768e-02, 5.8802e-01, 1.2138e-08, 4.2902e-09,\n",
       "        2.4035e-10, 1.0108e-11, 1.7069e-06, 7.2179e-06, 6.6518e-14, 5.0524e-10,\n",
       "        3.4076e-12, 1.1541e-17, 1.9069e-05, 9.9405e-07, 7.9744e-08, 6.2392e-04,\n",
       "        1.7824e-07, 1.8046e-08], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve the probabilities of the next characters\n",
    "probs[torch.arange(len(Y)), Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.2359, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# calculate the loss\n",
    "loss = -probs[torch.arange(len(Y)), Y].log().mean()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize the above steps into a function\n",
    "def forward(X, C_lookup, W1, b1, W2, b2):\n",
    "    # embedding all the characters in the input sequences\n",
    "    X_embed = C_lookup[X]\n",
    "    # reshape the input sequences\n",
    "    X_embed = X_embed.view(-1, 6)\n",
    "    # calculate the hidden layer\n",
    "    H = torch.tanh(X_embed @ W1 + b1)\n",
    "    # calculate the output layer\n",
    "    logits = H @ W2 + b2\n",
    "    # use coross-entropy loss\n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the parameters\n",
    "g_seed = torch.Generator().manual_seed(666)\n",
    "C_lookup = torch.randn(len(char2int), 2, requires_grad=True, generator=g_seed)\n",
    "W1 = torch.randn(6, 100, requires_grad=True, generator=g_seed)\n",
    "b1 = torch.randn(100, requires_grad=True, generator=g_seed)\n",
    "W2 = torch.randn(100, len(char2int), requires_grad=True, generator=g_seed)\n",
    "b2 = torch.randn(len(char2int), requires_grad=True, generator=g_seed)\n",
    "parameters = [C_lookup, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total parameters: 3481\n"
     ]
    }
   ],
   "source": [
    "# calculate the total number of parameters\n",
    "total_params = sum(p.numel() for p in parameters)\n",
    "print('total parameters:', total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13.9521, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unpack the parameters with * operator\n",
    "# python is beautiful :)\n",
    "forward(X, *parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.155815839767456\n",
      "2.789224624633789\n",
      "2.4765310287475586\n",
      "2.209885358810425\n",
      "1.9780027866363525\n",
      "1.7717442512512207\n",
      "1.5868629217147827\n",
      "1.4226648807525635\n",
      "1.2795374393463135\n",
      "1.1573749780654907\n",
      "1.054980993270874\n",
      "0.9694474339485168\n",
      "0.8976451754570007\n",
      "0.8375321626663208\n",
      "0.7871580719947815\n",
      "0.7443479895591736\n",
      "0.7073003649711609\n",
      "0.6747673749923706\n",
      "0.6459058523178101\n",
      "0.6201291084289551\n",
      "0.5970106720924377\n",
      "0.57622230052948\n",
      "0.5574955344200134\n",
      "0.5405979156494141\n",
      "0.5253202319145203\n",
      "0.5114725828170776\n",
      "0.4988831877708435\n",
      "0.48740071058273315\n",
      "0.4768918752670288\n",
      "0.46724188327789307\n",
      "0.45835208892822266\n",
      "0.45013684034347534\n",
      "0.4425230622291565\n",
      "0.4354473650455475\n",
      "0.42885512113571167\n",
      "0.4226987361907959\n",
      "0.41693583130836487\n",
      "0.41153088212013245\n",
      "0.40645137429237366\n",
      "0.40166860818862915\n",
      "0.3971578776836395\n",
      "0.39289674162864685\n",
      "0.3888648748397827\n",
      "0.38504457473754883\n",
      "0.3814198672771454\n",
      "0.3779762089252472\n",
      "0.37470075488090515\n",
      "0.371581107378006\n",
      "0.3686072528362274\n",
      "0.3657689392566681\n",
      "0.36305734515190125\n",
      "0.3604642450809479\n",
      "0.35798221826553345\n",
      "0.35560446977615356\n",
      "0.35332486033439636\n",
      "0.3511371910572052\n",
      "0.3490365147590637\n",
      "0.347017765045166\n",
      "0.34507623314857483\n",
      "0.34320777654647827\n",
      "0.3414084017276764\n",
      "0.33967477083206177\n",
      "0.33800292015075684\n",
      "0.3363898992538452\n",
      "0.33483296632766724\n",
      "0.33332908153533936\n",
      "0.33187592029571533\n",
      "0.3304708003997803\n",
      "0.32911157608032227\n",
      "0.3277961313724518\n",
      "0.32652223110198975\n",
      "0.3252882957458496\n",
      "0.32409244775772095\n",
      "0.3229329586029053\n",
      "0.3218082785606384\n",
      "0.3207167983055115\n",
      "0.3196573257446289\n",
      "0.3186282813549042\n",
      "0.31762874126434326\n",
      "0.316657155752182\n",
      "0.3157126009464264\n",
      "0.31479403376579285\n",
      "0.31390026211738586\n",
      "0.31303054094314575\n",
      "0.31218376755714417\n",
      "0.3113592565059662\n",
      "0.3105558454990387\n",
      "0.30977311730384827\n",
      "0.3090100586414337\n",
      "0.3082661032676697\n",
      "0.30754050612449646\n",
      "0.3068326711654663\n",
      "0.3061418831348419\n",
      "0.3054676353931427\n",
      "0.3048093020915985\n",
      "0.30416637659072876\n",
      "0.30353835225105286\n",
      "0.30292463302612305\n",
      "0.30232489109039307\n",
      "0.30173859000205994\n"
     ]
    }
   ],
   "source": [
    "# let's train the model\n",
    "for _ in range(100):\n",
    "    loss = forward(X, *parameters)\n",
    "    # initialize the gradients\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    # backpropagation\n",
    "    loss.backward()\n",
    "    # update the parameters\n",
    "    for p in parameters:\n",
    "        p.data -= 0.1 * p.grad\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
