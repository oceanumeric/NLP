{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Michael/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"learning% makes 'me' happy. i am happy be-cause i am learning! :)\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = \"Learning% makes 'me' happy. I am happy be-cause I am learning! :)\"\n",
    "corpus.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expression\n",
    "# match any symobls not in [a-zA-Z0-9.?! ]+\n",
    "corpus = re.sub(r\"[^a-zA-Z0-9.?! ]+\", \"\", corpus)\n",
    "corpus = corpus.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['learning',\n",
       " 'makes',\n",
       " 'me',\n",
       " 'happy',\n",
       " '.',\n",
       " 'i',\n",
       " 'am',\n",
       " 'happy',\n",
       " 'because',\n",
       " 'i',\n",
       " 'am',\n",
       " 'learning',\n",
       " '!']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list = nltk.word_tokenize(corpus)\n",
    "token_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence to n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['learning', 'makes', 'me']\n",
      "['makes', 'me', 'happy']\n",
      "['me', 'happy', '.']\n",
      "['happy', '.', 'i']\n",
      "['.', 'i', 'am']\n",
      "['i', 'am', 'happy']\n",
      "['am', 'happy', 'because']\n",
      "['happy', 'because', 'i']\n",
      "['because', 'i', 'am']\n",
      "['i', 'am', 'learning']\n",
      "['am', 'learning', '!']\n"
     ]
    }
   ],
   "source": [
    "def sentence_to_trigram(token_list):\n",
    "    for i in range(len(token_list)-2):\n",
    "        trigram = token_list[i:i+3]\n",
    "        print(trigram)\n",
    "sentence_to_trigram(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '<s>', 'learning', 'makes', 'me', 'happy', '.', 'i', 'am', 'happy', 'because', 'i', 'am', 'learning', '!', '</s>']\n"
     ]
    }
   ],
   "source": [
    "# add pre-fix and ending \n",
    "# bi-gram n = 2, trigram n = 3\n",
    "n = 3\n",
    "token_list = ['<s>'] * (n-1) + token_list + ['</s>']\n",
    "print(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '<s>', 'learning']\n",
      "['<s>', 'learning', 'makes']\n",
      "['learning', 'makes', 'me']\n",
      "['makes', 'me', 'happy']\n",
      "['me', 'happy', '.']\n",
      "['happy', '.', 'i']\n",
      "['.', 'i', 'am']\n",
      "['i', 'am', 'happy']\n",
      "['am', 'happy', 'because']\n",
      "['happy', 'because', 'i']\n",
      "['because', 'i', 'am']\n",
      "['i', 'am', 'learning']\n",
      "['am', 'learning', '!']\n",
      "['learning', '!', '</s>']\n"
     ]
    }
   ],
   "source": [
    "sentence_to_trigram(token_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing Matrix and Count frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict  # default dict with default value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_gram_matrix(corpus, n = 3):\n",
    "    \"\"\"\n",
    "    Create a n-gram matrix with corpus\n",
    "    Args:\n",
    "        corpus: Pre-processed and tokenized corpus. \n",
    "        n : n-gram, default value = 3 \n",
    "    \n",
    "    Returns:\n",
    "        bigrams: list of all bigram prefixes, row index\n",
    "        vocabulary: list of all found words, the column index\n",
    "        count_matrix: pandas dataframe with bigram prefixes as rows, \n",
    "                      vocabulary words as columns \n",
    "                      and the counts of the bigram/word combinations (i.e. trigrams) as values\n",
    "    \"\"\"\n",
    "    grams = []\n",
    "    vocabulary = []\n",
    "    count_matrix_dict = defaultdict(dict)\n",
    "    \n",
    "    for i in range(len(corpus)-n+1):\n",
    "        n_gram = tuple(corpus[i:i+n])\n",
    "        n_minus_1_gram = n_gram[:-1]\n",
    "        if n_minus_1_gram not in grams:\n",
    "            grams.append(n_minus_1_gram)\n",
    "        last_word = n_gram[-1]\n",
    "        if last_word not in vocabulary:\n",
    "            vocabulary.append(last_word)\n",
    "        # initialize the matrix     \n",
    "        pair = (n_minus_1_gram, last_word)\n",
    "        count_matrix_dict[pair] = count_matrix_dict.get(pair, 0) + 1\n",
    "            \n",
    "    # convert the count_matrix to np.array to fill in the blanks\n",
    "    matrix_shape = (len(grams), len(vocabulary))\n",
    "    count_matrix = np.zeros(matrix_shape)\n",
    "    for gram_key, gram_value in count_matrix_dict.items():\n",
    "        # grams.index() gives the index value based on the value \n",
    "        count_matrix[grams.index(gram_key[0]), vocabulary.index(gram_key[1])] = gram_value\n",
    "        \n",
    "    count_matrix = pd.DataFrame(count_matrix, index=grams, columns=vocabulary)\n",
    "    \n",
    "    return grams, vocabulary, count_matrix\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   learning  makes   me  happy    .    i   am  because    !  \\\n",
      "(<s>, <s>)              1.0    0.0  0.0    0.0  0.0  0.0  0.0      0.0  0.0   \n",
      "(<s>, learning)         0.0    1.0  0.0    0.0  0.0  0.0  0.0      0.0  0.0   \n",
      "(learning, makes)       0.0    0.0  1.0    0.0  0.0  0.0  0.0      0.0  0.0   \n",
      "(makes, me)             0.0    0.0  0.0    1.0  0.0  0.0  0.0      0.0  0.0   \n",
      "(me, happy)             0.0    0.0  0.0    0.0  1.0  0.0  0.0      0.0  0.0   \n",
      "(happy, .)              0.0    0.0  0.0    0.0  0.0  1.0  0.0      0.0  0.0   \n",
      "(., i)                  0.0    0.0  0.0    0.0  0.0  0.0  1.0      0.0  0.0   \n",
      "(i, am)                 1.0    0.0  0.0    1.0  0.0  0.0  0.0      0.0  0.0   \n",
      "(am, happy)             0.0    0.0  0.0    0.0  0.0  0.0  0.0      1.0  0.0   \n",
      "(happy, because)        0.0    0.0  0.0    0.0  0.0  1.0  0.0      0.0  0.0   \n",
      "(because, i)            0.0    0.0  0.0    0.0  0.0  0.0  1.0      0.0  0.0   \n",
      "(am, learning)          0.0    0.0  0.0    0.0  0.0  0.0  0.0      0.0  1.0   \n",
      "(learning, !)           0.0    0.0  0.0    0.0  0.0  0.0  0.0      0.0  0.0   \n",
      "\n",
      "                   </s>  \n",
      "(<s>, <s>)          0.0  \n",
      "(<s>, learning)     0.0  \n",
      "(learning, makes)   0.0  \n",
      "(makes, me)         0.0  \n",
      "(me, happy)         0.0  \n",
      "(happy, .)          0.0  \n",
      "(., i)              0.0  \n",
      "(i, am)             0.0  \n",
      "(am, happy)         0.0  \n",
      "(happy, because)    0.0  \n",
      "(because, i)        0.0  \n",
      "(am, learning)      0.0  \n",
      "(learning, !)       1.0  \n"
     ]
    }
   ],
   "source": [
    "test_g, test_v, test_matrix = n_gram_matrix(token_list)\n",
    "print(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             <s>  learning  makes   me  happy    .    i   am  because    !  \\\n",
      "(<s>,)       1.0       1.0    0.0  0.0    0.0  0.0  0.0  0.0      0.0  0.0   \n",
      "(learning,)  0.0       0.0    1.0  0.0    0.0  0.0  0.0  0.0      0.0  1.0   \n",
      "(makes,)     0.0       0.0    0.0  1.0    0.0  0.0  0.0  0.0      0.0  0.0   \n",
      "(me,)        0.0       0.0    0.0  0.0    1.0  0.0  0.0  0.0      0.0  0.0   \n",
      "(happy,)     0.0       0.0    0.0  0.0    0.0  1.0  0.0  0.0      1.0  0.0   \n",
      "(.,)         0.0       0.0    0.0  0.0    0.0  0.0  1.0  0.0      0.0  0.0   \n",
      "(i,)         0.0       0.0    0.0  0.0    0.0  0.0  0.0  2.0      0.0  0.0   \n",
      "(am,)        0.0       1.0    0.0  0.0    1.0  0.0  0.0  0.0      0.0  0.0   \n",
      "(because,)   0.0       0.0    0.0  0.0    0.0  0.0  1.0  0.0      0.0  0.0   \n",
      "(!,)         0.0       0.0    0.0  0.0    0.0  0.0  0.0  0.0      0.0  0.0   \n",
      "\n",
      "             </s>  \n",
      "(<s>,)        0.0  \n",
      "(learning,)   0.0  \n",
      "(makes,)      0.0  \n",
      "(me,)         0.0  \n",
      "(happy,)      0.0  \n",
      "(.,)          0.0  \n",
      "(i,)          0.0  \n",
      "(am,)         0.0  \n",
      "(because,)    0.0  \n",
      "(!,)          1.0  \n"
     ]
    }
   ],
   "source": [
    "test2_g, test2_v, test2_matrix = n_gram_matrix(token_list, n=2)\n",
    "print(test2_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<s>, <s>)           1.0\n",
       "(<s>, learning)      1.0\n",
       "(learning, makes)    1.0\n",
       "(makes, me)          1.0\n",
       "(me, happy)          1.0\n",
       "(happy, .)           1.0\n",
       "(., i)               1.0\n",
       "(i, am)              2.0\n",
       "(am, happy)          1.0\n",
       "(happy, because)     1.0\n",
       "(because, i)         1.0\n",
       "(am, learning)       1.0\n",
       "(learning, !)        1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vertically downwards across rows (axis 0)\n",
    "# running horizontally across columns (axis 1).\n",
    "row_sum = test_matrix.sum(axis=1)\n",
    "row_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning</th>\n",
       "      <th>makes</th>\n",
       "      <th>me</th>\n",
       "      <th>happy</th>\n",
       "      <th>.</th>\n",
       "      <th>i</th>\n",
       "      <th>am</th>\n",
       "      <th>because</th>\n",
       "      <th>!</th>\n",
       "      <th>&lt;/s&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(&lt;s&gt;, &lt;s&gt;)</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(&lt;s&gt;, learning)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(learning, makes)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(makes, me)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(me, happy)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(happy, .)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(., i)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i, am)</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(am, happy)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(happy, because)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(because, i)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(am, learning)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(learning, !)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   learning  makes   me  happy    .    i   am  because    !  \\\n",
       "(<s>, <s>)              1.0    0.0  0.0    0.0  0.0  0.0  0.0      0.0  0.0   \n",
       "(<s>, learning)         0.0    1.0  0.0    0.0  0.0  0.0  0.0      0.0  0.0   \n",
       "(learning, makes)       0.0    0.0  1.0    0.0  0.0  0.0  0.0      0.0  0.0   \n",
       "(makes, me)             0.0    0.0  0.0    1.0  0.0  0.0  0.0      0.0  0.0   \n",
       "(me, happy)             0.0    0.0  0.0    0.0  1.0  0.0  0.0      0.0  0.0   \n",
       "(happy, .)              0.0    0.0  0.0    0.0  0.0  1.0  0.0      0.0  0.0   \n",
       "(., i)                  0.0    0.0  0.0    0.0  0.0  0.0  1.0      0.0  0.0   \n",
       "(i, am)                 0.5    0.0  0.0    0.5  0.0  0.0  0.0      0.0  0.0   \n",
       "(am, happy)             0.0    0.0  0.0    0.0  0.0  0.0  0.0      1.0  0.0   \n",
       "(happy, because)        0.0    0.0  0.0    0.0  0.0  1.0  0.0      0.0  0.0   \n",
       "(because, i)            0.0    0.0  0.0    0.0  0.0  0.0  1.0      0.0  0.0   \n",
       "(am, learning)          0.0    0.0  0.0    0.0  0.0  0.0  0.0      0.0  1.0   \n",
       "(learning, !)           0.0    0.0  0.0    0.0  0.0  0.0  0.0      0.0  0.0   \n",
       "\n",
       "                   </s>  \n",
       "(<s>, <s>)          0.0  \n",
       "(<s>, learning)     0.0  \n",
       "(learning, makes)   0.0  \n",
       "(makes, me)         0.0  \n",
       "(me, happy)         0.0  \n",
       "(happy, .)          0.0  \n",
       "(., i)              0.0  \n",
       "(i, am)             0.0  \n",
       "(am, happy)         0.0  \n",
       "(happy, because)    0.0  \n",
       "(because, i)        0.0  \n",
       "(am, learning)      0.0  \n",
       "(learning, !)       1.0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_matrix = test_matrix.div(row_sum, axis=0)\n",
    "prob_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'learning makes me happy. i am happy because i am learning! '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the probability\n",
    "# this is the population\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram = ('i', 'am', 'happy')\n",
    "bigram = trigram[:-1]\n",
    "word = trigram[-1]\n",
    "prob_matrix[word][bigram]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "def sample_split(data, train_percent, validation_percent):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        data: list of sentence\n",
    "        train_percent: e.g. 60%\n",
    "        validation_percent: e.g. 30%\n",
    "    Note: train_percent + validation_percent <= 100 \n",
    "    Output:\n",
    "        train_data: list of sentences \n",
    "        validation_data\n",
    "        test_data\n",
    "    \"\"\"\n",
    "    random.seed(87)\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    train_size = int(len(data) * train_percent /100)\n",
    "    train_data = data[:train_size]\n",
    "    \n",
    "    validation_size = int(len(data) * validation_percent / 100)\n",
    "    validataion_data = data[train_size:train_size+validation_size]\n",
    "    \n",
    "    test_data = data[train_size+validation_size:]\n",
    "    \n",
    "    return train_data, validataion_data, test_data \n",
    "\n",
    "data = [x for x in range(0, 100)]\n",
    "train_data, _, _ = sample_split(data, 60, 20)\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out of vocabulary words\n",
    "\n",
    "We use \\<UNK\\> to replace the out of vocabulary words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity for the training set: 1.2599210498948732\n",
      "perplexity for the training set with <UNK>: 1.0\n"
     ]
    }
   ],
   "source": [
    "# if there are many <unk> replaces in your train and test set, you may get a very low perplexity\n",
    "# even though the model itsef wouldn't be helpful\n",
    "training_set = ['i', 'am', 'happy', 'because','i', 'am', 'learning', '.']\n",
    "training_set_unk = ['i', 'am', '<UNK>', '<UNK>','i', 'am', '<UNK>', '<UNK>']\n",
    "\n",
    "test_set = ['i', 'am', 'learning']\n",
    "test_set_unk = ['i', 'am', '<UNK>']\n",
    "\n",
    "# initialize the results \n",
    "M = len(test_set)\n",
    "prob = 1\n",
    "prob_unk = 1\n",
    "\n",
    "# many <unk> low perplexity \n",
    "training_set = ['i', 'am', 'happy', 'because','i', 'am', 'learning', '.']\n",
    "training_set_unk = ['i', 'am', '<UNK>', '<UNK>','i', 'am', '<UNK>', '<UNK>']\n",
    "\n",
    "test_set = ['i', 'am', 'learning']\n",
    "test_set_unk = ['i', 'am', '<UNK>']\n",
    "\n",
    "M = len(test_set)\n",
    "probability = 1\n",
    "probability_unk = 1\n",
    "\n",
    "# pre-calculated probabilities\n",
    "bigram_probabilities = {('i', 'am'): 1.0, ('am', 'happy'): 0.5, \n",
    "                        ('happy', 'because'): 1.0, \n",
    "                        ('because', 'i'): 1.0, \n",
    "                        ('am', 'learning'): 0.5, \n",
    "                        ('learning', '.'): 1.0}\n",
    "bigram_probabilities_unk = {('i', 'am'): 1.0, \n",
    "                            ('am', '<UNK>'): 1.0, \n",
    "                            ('<UNK>', '<UNK>'): 0.5, ('<UNK>', 'i'): 0.25}\n",
    "\n",
    "for i in range(len(test_set) -1):\n",
    "    bigram = tuple(test_set[i:i+2])\n",
    "    prob = prob * bigram_probabilities[bigram]  # intersection probability \n",
    "    \n",
    "    bigram_unk = tuple(test_set_unk[i:i+2])\n",
    "    prob_unk = prob_unk * bigram_probabilities_unk[bigram_unk]\n",
    "    \n",
    "# calculate perplexity\n",
    "perplexity = prob ** (-1/M)   # average probability for an independent event\n",
    "perplexity_unk = prob_unk ** (-1/M)\n",
    "\n",
    "print(f\"perplexity for the training set: {perplexity}\")\n",
    "print(f\"perplexity for the training set with <UNK>: {perplexity_unk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__comment__: the lower perplexity, the closer it is to human speech "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoothing \n",
    "def add_k_smoothing_prob(k, vocabulary_size, n_gram_count, n_gram_prefix_count):\n",
    "    numerator = n_gram_count + k \n",
    "    denominator = n_gram_prefix_count + k * vocabulary_size  # proportional to size \n",
    "    \n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "besides the trigram ('are', 'you', 'happy') we also use back-off ('you', 'happy') and happy\n"
     ]
    }
   ],
   "source": [
    "# back-off \n",
    "trigram_p = {('i', 'am', 'happy'):0}\n",
    "bigram_p = {('am', 'happy'):0.3}\n",
    "unigram_p = {('happy'):0.4}\n",
    "\n",
    "trigram_test = ('are', 'you', 'happy')\n",
    "\n",
    "bigram_back_off = trigram_test[1:3]\n",
    "unigram_back_off = trigram_test[2]\n",
    "\n",
    "print(f\"besides the trigram {trigram_test} we also use back-off {bigram_back_off} and {unigram_back_off}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability for ('are', 'you', 'happy') Not found\n",
      "probability for ('you', 'happy') Not found\n",
      "probability of unigram happy Found\n",
      "\n",
      "probability for trigram ('are', 'you', 'happy') estimated as 0.06400000000000002\n"
     ]
    }
   ],
   "source": [
    "lambda_factor = 0.4  # back-off factor\n",
    "trigram_estimated_prob = 0  # initialize the probability\n",
    "\n",
    "if trigram_test not in trigram_p or trigram_p[trigram_test] == 0:\n",
    "    print(f\"probability for {trigram_test} Not found\")\n",
    "    \n",
    "    if bigram_back_off not in bigram_p or bigram_p[bigram_back_off] == 0:\n",
    "        print(f\"probability for {bigram_back_off} Not found\")\n",
    "        \n",
    "        if unigram_back_off in unigram_p:\n",
    "            print(f\"probability of unigram {unigram_back_off} Found\\n\") \n",
    "            trigram_estimated_prob = lambda_factor * lambda_factor * unigram_p[unigram_back_off]\n",
    "        else:\n",
    "            trigram_estimated_prob = 0\n",
    "    else: \n",
    "        trigram_estimated_prob = lambda_factor * bigram_p[bigram_back_off]\n",
    "    \n",
    "else:\n",
    "    trigram_estimated_prob = trigram_p[trigram_test]\n",
    "    \n",
    "print(f\"probability for trigram {trigram_test} estimated as {trigram_estimated_prob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation\n",
    "# more like weighted average of probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b30f1e37ab6bb31f04d49272996ab097d78250cb126a8dec2a7497893895f41"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
